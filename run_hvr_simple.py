#!/usr/bin/env python3
"""
ç®€åŒ–çš„HVRè®­ç»ƒå¯åŠ¨è„šæœ¬

ç›´æ¥ä½¿ç”¨Pythonå­—å…¸é…ç½®ï¼Œé¿å…å¤æ‚çš„Hydraé…ç½®ç³»ç»Ÿ
"""

import os
import sys
import ray
from omegaconf import OmegaConf

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

from verl.trainer.hvr.hvr_trainer import HVRTrainer
from verl.trainer.ppo.core_algos import is_main_process


def create_hvr_config():
    """åˆ›å»ºHVRé…ç½®"""
    config = {
        # è®­ç»ƒå™¨é…ç½®
        "trainer": {
            "project_name": "HVR-IntrinsicReward",
            "experiment_name": "HVR_ERVF_Pure_Test",
            "nnodes": 1,
            "n_gpus_per_node": 1,
            "total_epochs": 8,
            "save_freq": 2,
            "test_freq": 1,
            "logger": ["wandb"],
            "default_local_dir": "/root/autodl-tmp/myverl/ckpts/HVR_Pure",
            "critic_warmup": 0,
        },
        
        # Actoré…ç½®
        "actor_rollout_ref": {
            "actor": {
                "optim": {
                    "lr": 3e-6,
                    "weight_decay": 0.01,
                },
                "ppo_mini_batch_size": 8,
                "ppo_micro_batch_size_per_gpu": 4,
                "use_remove_padding": False,  # HVRå¿…éœ€
                
                # HVRæ ¸å¿ƒå‚æ•°
                "hvr_alpha": 1.0,
                "hvr_beta": 0.1,
                "hvr_lambda": 0.5,
                "hvr_cliprange": 0.2,
                
                # FSDPé…ç½®
                "fsdp_config": {
                    "param_offload": True,
                    "optimizer_offload": True,
                },
                "grad_clip": 1.0,
                
                # ç¦ç”¨å…¶ä»–åˆ›æ–°ç‚¹
                "use_ema_smoothing": False,
                "use_gradient_adaptive_weighting": False,
                "use_amic": False,
                "use_ptrw": False,
                "use_temporal_decay": False,
                "use_sca": False,
                "use_asymmetric_clipping": False,
            },
            
            # æ¨¡å‹é…ç½®
            "model": {
                "path": "/root/autodl-tmp/myverl/mymodels/qwen3-0.6b",
                "use_remove_padding": False,
                "enable_gradient_checkpointing": True,
            },
            
            # Rollouté…ç½®
            "rollout": {
                "name": "vllm",
                "gpu_memory_utilization": 0.5,
                "n": 8,
                "log_prob_micro_batch_size_per_gpu": 8,
                "max_num_batched_tokens": 16384,
                "tensor_model_parallel_size": 1,
            },
            
            # Referenceé…ç½®
            "ref": {
                "log_prob_micro_batch_size_per_gpu": 8,
                "fsdp_config": {
                    "param_offload": False,
                },
            },
        },
        
        # æ•°æ®é…ç½®
        "data": {
            "train_files": "/root/autodl-tmp/myverl/data/kk/4ppl_few/train.parquet",
            "val_files": "/root/autodl-tmp/myverl/data/kk/4ppl_few/test.parquet",
            "train_batch_size": 16,
            "val_batch_size": 8,
            "max_prompt_length": 4096,
            "max_response_length": 2048,
        },
        
        # å¥–åŠ±æ¨¡å‹é…ç½®
        "reward_model": {
            "reward_manager": "logic_rl",
        },
        
        # ç®—æ³•é…ç½®
        "algorithm": {
            "adv_estimator": "hvr",
            "kl_ctrl": {
                "kl_coef": 0.05,
            },
        },
    }
    
    return OmegaConf.create(config)


def validate_hvr_config(config):
    """éªŒè¯HVRé…ç½®"""
    if is_main_process():
        print("ğŸ” [HVR] éªŒè¯é…ç½®...")
    
    # æ£€æŸ¥å¿…éœ€çš„è·¯å¾„
    model_path = config.actor_rollout_ref.model.path
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
    
    train_files = config.data.train_files
    if not os.path.exists(train_files):
        raise FileNotFoundError(f"è®­ç»ƒæ•°æ®ä¸å­˜åœ¨: {train_files}")
    
    # éªŒè¯HVRå‚æ•°
    actor_config = config.actor_rollout_ref.actor
    assert 0 < actor_config.hvr_alpha <= 10, f"hvr_alphaåº”åœ¨(0,10]èŒƒå›´å†…"
    assert 0 <= actor_config.hvr_beta <= 1, f"hvr_betaåº”åœ¨[0,1]èŒƒå›´å†…"
    assert 0 <= actor_config.hvr_lambda <= 1, f"hvr_lambdaåº”åœ¨[0,1]èŒƒå›´å†…"
    
    if is_main_process():
        print("âœ… [HVR] é…ç½®éªŒè¯å®Œæˆ")


def run_hvr_training():
    """è¿è¡ŒHVRè®­ç»ƒ"""
    if is_main_process():
        print("ğŸ¯ [HVR] å¯åŠ¨HVRå†…ç”Ÿå¥–åŠ±è®­ç»ƒ")
        print("ğŸ¯ [HVRç‰¹æ€§] ERVFä»·å€¼å‡½æ•° + åè§ä¹‹æ˜ä»·å€¼é‡å¡‘")
    
    try:
        # åˆ›å»ºé…ç½®
        config = create_hvr_config()
        
        # éªŒè¯é…ç½®
        validate_hvr_config(config)
        
        if is_main_process():
            print(f"ğŸ¯ [HVRå‚æ•°] Î±={config.actor_rollout_ref.actor.hvr_alpha}")
            print(f"ğŸ¯ [HVRå‚æ•°] Î²={config.actor_rollout_ref.actor.hvr_beta}")
            print(f"ğŸ¯ [HVRå‚æ•°] Î»={config.actor_rollout_ref.actor.hvr_lambda}")
        
        # åˆå§‹åŒ–Ray
        if not ray.is_initialized():
            ray.init()
        
        # åˆ›å»ºHVRè®­ç»ƒå™¨
        trainer = HVRTrainer(config)
        
        # åˆå§‹åŒ–workers
        trainer.init_workers()
        
        # å¼€å§‹è®­ç»ƒ
        trainer.fit()
        
        if is_main_process():
            print("ğŸ‰ [HVR] HVRè®­ç»ƒå®Œæˆï¼")
            
    except Exception as e:
        if is_main_process():
            print(f"âŒ [HVR] è®­ç»ƒå¤±è´¥: {e}")
        raise
    finally:
        # æ¸…ç†Rayèµ„æº
        if ray.is_initialized():
            ray.shutdown()


if __name__ == "__main__":
    # è®¾ç½®ç¯å¢ƒå˜é‡
    os.environ["VLLM_ATTENTION_BACKEND"] = "XFORMERS"
    
    print("ğŸš€ [HVR] å¯åŠ¨HVRçº¯å‡€å†…ç”Ÿå¥–åŠ±è®­ç»ƒç³»ç»Ÿ")
    print("ğŸ¯ [HVRä¼˜åŠ¿] æ— éœ€criticç½‘ç»œï¼ŒåŸºäºæ¨¡å‹è‡ªèº«logitsçš„å†…ç”Ÿä»·å€¼ä¼°è®¡")
    
    run_hvr_training()
