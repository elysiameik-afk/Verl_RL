#!/usr/bin/env python3
"""
æµ‹è¯•HVRåœ¨GRPOæ¡†æ¶ä¸­çš„é›†æˆå®ç°

éªŒè¯ERVFä»·å€¼å‡½æ•°å’ŒHVRå¥–åŠ±é‡å¡‘åœ¨GRPOä¸­çš„æ­£ç¡®æ€§
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from verl.trainer.ppo.core_algos import (
    calculate_ervf_value,
    calculate_hvr_rewards_for_group,
    aggregate_hvr_metrics_dict
)

def test_ervf_value_function():
    """æµ‹è¯•ERVFä»·å€¼å‡½æ•°"""
    print("ğŸ”¬ æµ‹è¯•ERVF (ç†µæ­£åˆ™åŒ–ä»·å€¼å‡½æ•°)\n")
    
    # åˆ›å»ºæµ‹è¯•logits
    vocab_size = 1000
    logits = torch.randn(vocab_size)
    
    # æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆ
    test_cases = [
        (1.0, 0.0, "æ— ç†µæƒ©ç½š"),
        (1.0, 0.1, "è½»å¾®ç†µæƒ©ç½š"),
        (1.0, 0.5, "ä¸­ç­‰ç†µæƒ©ç½š"),
        (0.5, 0.1, "ä½æ¸©åº¦"),
        (2.0, 0.1, "é«˜æ¸©åº¦"),
    ]
    
    for alpha, beta, description in test_cases:
        v_ervf, entropy = calculate_ervf_value(logits, alpha, beta)
        
        # æ‰‹åŠ¨éªŒè¯è®¡ç®—
        v_endo = alpha * torch.logsumexp(logits / alpha, dim=0).item()
        expected_v_ervf = v_endo - beta * entropy
        
        print(f"ğŸ“Š {description} (Î±={alpha}, Î²={beta}):")
        print(f"  V_ERVF: {v_ervf:.4f}")
        print(f"  V_endo: {v_endo:.4f}")
        print(f"  ç†µ: {entropy:.4f}")
        print(f"  éªŒè¯: {'âœ…' if abs(v_ervf - expected_v_ervf) < 1e-6 else 'âŒ'}")
        print()

def test_hvr_group_processing():
    """æµ‹è¯•HVRç»„å¤„ç† (GRPOé›†æˆç‰ˆæœ¬)"""
    print("ğŸ¯ æµ‹è¯•HVRç»„å¤„ç† (GRPOé›†æˆç‰ˆæœ¬)\n")

    # åˆ›å»ºç»„æ•°æ® (æ¨¡æ‹ŸGRPOçš„ä¸€ä¸ªç»„)
    group_size = 4
    group_data = []

    # æµ‹è¯•logic_rlçš„å…¸å‹å¥–åŠ±å€¼
    logic_rl_rewards = [-3, -1, 1, 3]

    for i in range(group_size):
        seq_len = np.random.randint(8, 16)  # éšæœºåºåˆ—é•¿åº¦
        vocab_size = 1000

        # åˆ›å»ºå•ä¸ªåºåˆ—æ•°æ®
        logits = torch.randn(seq_len, vocab_size)
        ids = torch.randint(0, vocab_size, (seq_len,))
        r_final = logic_rl_rewards[i]  # ä½¿ç”¨ä¸åŒçš„å¥–åŠ±

        group_data.append({
            'logits': logits,
            'ids': ids,
            'r_final': r_final
        })

    print(f"ğŸ“Š ç»„æ•°æ®: {group_size} ä¸ªåºåˆ—")
    print(f"   ç¨€ç–å¥–åŠ±: {[d['r_final'] for d in group_data]}")

    # è®¡ç®—HVRç»„å›æŠ¥
    group_returns, hvr_metrics = calculate_hvr_rewards_for_group(
        group_data=group_data,
        alpha=1.0,
        beta=0.1,
        lambda_hvr=0.5
    )

    # è®¡ç®—GRPOä¼˜åŠ¿
    mean_return = sum(group_returns) / len(group_returns)
    grpo_advantages = [ret - mean_return for ret in group_returns]

    print(f"\nâœ… HVRç»„å¤„ç†ç»“æœ:")
    print(f"   ç»„å›æŠ¥: {[f'{ret:.4f}' for ret in group_returns]}")
    print(f"   å¹³å‡å›æŠ¥: {mean_return:.4f}")
    print(f"   GRPOä¼˜åŠ¿: {[f'{adv:.4f}' for adv in grpo_advantages]}")

    # èšåˆæŒ‡æ ‡
    aggregated_metrics = aggregate_hvr_metrics_dict(hvr_metrics)
    print(f"\nğŸ“Š HVRæŒ‡æ ‡:")
    for key, value in aggregated_metrics.items():
        if isinstance(value, (int, float)):
            print(f"   {key}: {value:.4f}")
        else:
            print(f"   {key}: {value}")

    print()

def test_hvr_parameter_sensitivity():
    """æµ‹è¯•HVRå‚æ•°æ•æ„Ÿæ€§"""
    print("ğŸ›ï¸ æµ‹è¯•HVRå‚æ•°æ•æ„Ÿæ€§\n")
    
    # å›ºå®šæµ‹è¯•æ•°æ®
    seq_len = 10
    vocab_size = 50
    response_logits = torch.randn(seq_len, vocab_size)
    response_ids = torch.randint(0, vocab_size, (seq_len,))
    r_final = 1.0
    
    # æµ‹è¯•Î±å‚æ•°å½±å“
    print("ğŸ“ˆ Î± (æ¸©åº¦ç³»æ•°) å‚æ•°å½±å“:")
    alphas = [0.5, 1.0, 2.0, 4.0]
    for alpha in alphas:
        hvr_rewards, metrics = calculate_hvr_rewards(
            response_logits, response_ids, r_final,
            alpha=alpha, beta=0.1, lambda_hvr=0.5
        )
        print(f"  Î±={alpha}: å¥–åŠ±å‡å€¼={hvr_rewards.mean().item():.4f}, "
              f"ERVFå‡å€¼={metrics.ervf_value_mean:.4f}")
    
    print("\nğŸ“ˆ Î² (ç†µæƒ©ç½š) å‚æ•°å½±å“:")
    betas = [0.0, 0.05, 0.1, 0.2, 0.5]
    for beta in betas:
        hvr_rewards, metrics = calculate_hvr_rewards(
            response_logits, response_ids, r_final,
            alpha=1.0, beta=beta, lambda_hvr=0.5
        )
        print(f"  Î²={beta}: å¥–åŠ±å‡å€¼={hvr_rewards.mean().item():.4f}, "
              f"ç†µå‡å€¼={metrics.entropy_mean:.4f}")
    
    print("\nğŸ“ˆ Î» (æ··åˆå› å­) å‚æ•°å½±å“:")
    lambdas = [0.0, 0.3, 0.5, 0.7, 1.0]
    for lambda_hvr in lambdas:
        hvr_rewards, metrics = calculate_hvr_rewards(
            response_logits, response_ids, r_final,
            alpha=1.0, beta=0.1, lambda_hvr=lambda_hvr
        )
        print(f"  Î»={lambda_hvr}: å¥–åŠ±å‡å€¼={hvr_rewards.mean().item():.4f}, "
              f"é‡å¡‘æ¯”ä¾‹={metrics.value_reshaping_ratio:.1f}")

def test_hvr_policy_loss():
    """æµ‹è¯•HVRç­–ç•¥æŸå¤±"""
    print("\nğŸ”§ æµ‹è¯•HVRç­–ç•¥æŸå¤±è®¡ç®—\n")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size = 2
    seq_len = 5
    
    log_probs = torch.randn(batch_size, seq_len)
    hvr_rewards = torch.randn(batch_size, seq_len)
    response_mask = torch.ones(batch_size, seq_len)
    response_mask[0, 3:] = 0  # ç¬¬ä¸€ä¸ªåºåˆ—é•¿åº¦ä¸º3
    response_mask[1, 4:] = 0  # ç¬¬äºŒä¸ªåºåˆ—é•¿åº¦ä¸º4
    
    # è®¡ç®—ç­–ç•¥æŸå¤±
    policy_loss, metrics = hvr_policy_loss(
        log_probs=log_probs,
        hvr_rewards=hvr_rewards,
        response_mask=response_mask,
        cliprange=0.2,
        loss_agg_mode="token-mean",
    )
    
    print(f"ç­–ç•¥æŸå¤±: {policy_loss.item():.6f}")
    print(f"HVRä¼˜åŠ¿å‡å€¼: {metrics['hvr_advantages_mean']:.6f}")
    print(f"Logæ¦‚ç‡å‡å€¼: {metrics['hvr_log_probs_mean']:.6f}")

def test_metrics_aggregation():
    """æµ‹è¯•æŒ‡æ ‡èšåˆ"""
    print("\nğŸ“Š æµ‹è¯•æŒ‡æ ‡èšåˆ\n")
    
    # åˆ›å»ºå¤šä¸ªåºåˆ—çš„æŒ‡æ ‡
    from verl.trainer.hvr.hvr_core_algos import HVRMetrics
    
    metrics_list = []
    for i in range(3):
        metrics = HVRMetrics(
            ervf_value_mean=1.0 + i * 0.1,
            entropy_mean=2.0 + i * 0.1,
            hvr_reward_mean=0.5 + i * 0.1,
            r_final_mean=[-1, 0, 1][i],
            total_sequences=1,
            successful_hvr_count=1,
            success_rate=1.0,
        )
        metrics_list.append(metrics)
    
    # èšåˆæŒ‡æ ‡
    aggregated = aggregate_hvr_metrics(metrics_list)
    
    print("èšåˆåçš„æŒ‡æ ‡:")
    for key, value in aggregated.items():
        print(f"  {key}: {value}")

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\nğŸ” æµ‹è¯•è¾¹ç•Œæƒ…å†µ\n")
    
    # æµ‹è¯•æçŸ­åºåˆ—
    print("ğŸ“ æçŸ­åºåˆ— (é•¿åº¦=1):")
    short_logits = torch.randn(1, 100)
    short_ids = torch.randint(0, 100, (1,))
    short_rewards, short_metrics = calculate_hvr_rewards(short_logits, short_ids, 1.0)
    print(f"  å¥–åŠ±: {short_rewards.tolist()}")
    print(f"  æˆåŠŸç‡: {short_metrics.success_rate}")
    
    # æµ‹è¯•æç«¯R_finalå€¼
    print("\nğŸ“Š æç«¯R_finalå€¼:")
    normal_logits = torch.randn(3, 100)
    normal_ids = torch.randint(0, 100, (3,))
    
    extreme_r_finals = [-3.0, 3.0]
    for r_final in extreme_r_finals:
        rewards, _ = calculate_hvr_rewards(normal_logits, normal_ids, r_final)
        print(f"  R_final={r_final}: å¥–åŠ±èŒƒå›´=[{rewards.min().item():.3f}, {rewards.max().item():.3f}]")
    
    # æµ‹è¯•æ•°å€¼ç¨³å®šæ€§
    print("\nğŸ”¢ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•:")
    large_logits = torch.randn(3, 100) * 10  # å¤§logits
    large_rewards, _ = calculate_hvr_rewards(large_logits, normal_ids, 0.0)
    print(f"  å¤§logits: NaNæ£€æŸ¥={'âŒ' if torch.isnan(large_rewards).any() else 'âœ…'}")
    print(f"  å¤§logits: Infæ£€æŸ¥={'âŒ' if torch.isinf(large_rewards).any() else 'âœ…'}")

def visualize_hvr_comparison():
    """å¯è§†åŒ–HVR vs æ ‡å‡†æ–¹æ³•å¯¹æ¯”"""
    try:
        print("\nğŸ“Š ç”ŸæˆHVRå¯¹æ¯”å¯è§†åŒ–...\n")
        
        seq_len = 20
        vocab_size = 100
        response_logits = torch.randn(seq_len, vocab_size)
        response_ids = torch.randint(0, vocab_size, (seq_len,))
        
        # ä¸åŒÎ»å€¼çš„HVRå¥–åŠ±
        lambdas = [0.0, 0.3, 0.5, 0.7, 1.0]
        
        plt.figure(figsize=(12, 8))
        
        for i, lambda_hvr in enumerate(lambdas):
            hvr_rewards, _ = calculate_hvr_rewards(
                response_logits, response_ids, 1.0,
                alpha=1.0, beta=0.1, lambda_hvr=lambda_hvr
            )
            
            plt.subplot(2, 3, i + 1)
            plt.plot(hvr_rewards.numpy(), 'o-', linewidth=2)
            plt.title(f'Î» = {lambda_hvr}')
            plt.xlabel('Tokenä½ç½®')
            plt.ylabel('HVRå¥–åŠ±')
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('hvr_comparison.png', dpi=150, bbox_inches='tight')
        print("  å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜ä¸º hvr_comparison.png")
        
    except ImportError:
        print("  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•HVRçº¯å‡€ç®—æ³•å®ç°\n")
    
    test_ervf_value_function()
    test_hvr_group_processing()
    test_hvr_parameter_sensitivity()
    test_edge_cases()
    visualize_hvr_comparison()
    
    print("ğŸ‰ HVR-GRPOé›†æˆç®—æ³•æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ“‹ HVRåœ¨GRPOæ¡†æ¶ä¸­çš„ç‰¹æ€§æ€»ç»“:")
    print("  âœ… ERVFä»·å€¼å‡½æ•°: åŸºäºlogitsçš„å†…ç”Ÿä»·å€¼ + ç†µæ­£åˆ™åŒ–")
    print("  âœ… HVRå¥–åŠ±é‡å¡‘: ç¨€ç–å¥–åŠ±æŒ‡å¯¼çš„ä»·å€¼è½¨è¿¹é‡å¡‘")
    print("  âœ… GRPOç»„é—´æŠ•ç¥¨: ä¿ç•™ç»„å†…ç›¸å¯¹ä¼˜åŠ¿è®¡ç®—")
    print("  âœ… æ— éœ€critic: å®Œå…¨åŸºäºæ¨¡å‹è‡ªèº«çš„å†…ç”Ÿä»·å€¼ä¼°è®¡")
    print("  âœ… Logic RLå…¼å®¹: æ”¯æŒ{-3,-1,0,1,3}ç­‰ç¨€ç–å¥–åŠ±")
    print("  âœ… å‚æ•°å¯æ§: Î±æ§åˆ¶æ¸©åº¦ï¼ŒÎ²æ§åˆ¶ç†µæƒ©ç½šï¼ŒÎ»æ§åˆ¶é‡å¡‘å¼ºåº¦")
    print("  âœ… æ•°å€¼ç¨³å®š: ä½¿ç”¨log_softmaxç­‰ç¨³å®šè®¡ç®—")
    print("\nğŸ¯ HVR-GRPOé›†æˆå†…ç”Ÿå¥–åŠ±ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼")
