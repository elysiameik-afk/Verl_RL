#!/usr/bin/env python3
"""
æµ‹è¯•HVR Managerçš„é›†æˆå®ç°

éªŒè¯HVR Logic RL Managerçš„æ­£ç¡®æ€§å’Œå®Œæ•´æ€§
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from verl.trainer.ppo.core_algos import (
    calculate_ervf_value,
    calculate_hvr_rewards_for_group,
    aggregate_hvr_metrics_dict
)

# æµ‹è¯•HVR Manager
def test_hvr_manager():
    """æµ‹è¯•HVR Managerçš„åŸºæœ¬åŠŸèƒ½"""
    print("ğŸ¯ æµ‹è¯•HVR Manager\n")

    try:
        from verl.trainer.ppo.reward_manager.hvr_logic_rl_reward import HVRLogicRLRewardManager

        # åˆ›å»ºHVR Manager
        manager = HVRLogicRLRewardManager(
            tokenizer=None,  # ç®€åŒ–æµ‹è¯•
            num_examine=1,
            hvr_alpha=1.0,
            hvr_beta=0.1,
            hvr_lambda=0.5
        )

        print("âœ… HVR Manageråˆ›å»ºæˆåŠŸ")
        print(f"   å‚æ•°: Î±={manager.hvr_alpha}, Î²={manager.hvr_beta}, Î»={manager.hvr_lambda}")

        return True

    except Exception as e:
        print(f"âŒ HVR Manageræµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ervf_value_function():
    """æµ‹è¯•ERVFä»·å€¼å‡½æ•°"""
    print("ğŸ”¬ æµ‹è¯•ERVF (ç†µæ­£åˆ™åŒ–ä»·å€¼å‡½æ•°)\n")
    
    # åˆ›å»ºæµ‹è¯•logits
    vocab_size = 1000
    logits = torch.randn(vocab_size)
    
    # æµ‹è¯•ä¸åŒå‚æ•°ç»„åˆ
    test_cases = [
        (1.0, 0.0, "æ— ç†µæƒ©ç½š"),
        (1.0, 0.1, "è½»å¾®ç†µæƒ©ç½š"),
        (1.0, 0.5, "ä¸­ç­‰ç†µæƒ©ç½š"),
        (0.5, 0.1, "ä½æ¸©åº¦"),
        (2.0, 0.1, "é«˜æ¸©åº¦"),
    ]
    
    for alpha, beta, description in test_cases:
        v_ervf, entropy = calculate_ervf_value(logits, alpha, beta)
        
        # æ‰‹åŠ¨éªŒè¯è®¡ç®—
        v_endo = alpha * torch.logsumexp(logits / alpha, dim=0).item()
        expected_v_ervf = v_endo - beta * entropy
        
        print(f"ğŸ“Š {description} (Î±={alpha}, Î²={beta}):")
        print(f"  V_ERVF: {v_ervf:.4f}")
        print(f"  V_endo: {v_endo:.4f}")
        print(f"  ç†µ: {entropy:.4f}")
        print(f"  éªŒè¯: {'âœ…' if abs(v_ervf - expected_v_ervf) < 1e-6 else 'âŒ'}")
        print()

def test_hvr_group_processing():
    """æµ‹è¯•HVRç»„å¤„ç† (GRPOé›†æˆç‰ˆæœ¬)"""
    print("ğŸ¯ æµ‹è¯•HVRç»„å¤„ç† (GRPOé›†æˆç‰ˆæœ¬)\n")

    # åˆ›å»ºç»„æ•°æ® (æ¨¡æ‹ŸGRPOçš„ä¸€ä¸ªç»„)
    group_size = 4
    group_data = []

    # æµ‹è¯•logic_rlçš„å…¸å‹å¥–åŠ±å€¼
    logic_rl_rewards = [-3, -1, 1, 3]

    for i in range(group_size):
        seq_len = np.random.randint(8, 16)  # éšæœºåºåˆ—é•¿åº¦
        vocab_size = 1000

        # åˆ›å»ºå•ä¸ªåºåˆ—æ•°æ®
        logits = torch.randn(seq_len, vocab_size)
        ids = torch.randint(0, vocab_size, (seq_len,))
        r_final = logic_rl_rewards[i]  # ä½¿ç”¨ä¸åŒçš„å¥–åŠ±

        group_data.append({
            'logits': logits,
            'ids': ids,
            'r_final': r_final
        })

    print(f"ğŸ“Š ç»„æ•°æ®: {group_size} ä¸ªåºåˆ—")
    print(f"   ç¨€ç–å¥–åŠ±: {[d['r_final'] for d in group_data]}")

    # è®¡ç®—HVRç»„å›æŠ¥
    group_returns, hvr_metrics = calculate_hvr_rewards_for_group(
        group_data=group_data,
        alpha=1.0,
        beta=0.1,
        lambda_hvr=0.5
    )

    # è®¡ç®—GRPOä¼˜åŠ¿
    mean_return = sum(group_returns) / len(group_returns)
    grpo_advantages = [ret - mean_return for ret in group_returns]

    print(f"\nâœ… HVRç»„å¤„ç†ç»“æœ:")
    print(f"   ç»„å›æŠ¥: {[f'{ret:.4f}' for ret in group_returns]}")
    print(f"   å¹³å‡å›æŠ¥: {mean_return:.4f}")
    print(f"   GRPOä¼˜åŠ¿: {[f'{adv:.4f}' for adv in grpo_advantages]}")

    # èšåˆæŒ‡æ ‡
    aggregated_metrics = aggregate_hvr_metrics_dict(hvr_metrics)
    print(f"\nğŸ“Š HVRæŒ‡æ ‡:")
    for key, value in aggregated_metrics.items():
        if isinstance(value, (int, float)):
            print(f"   {key}: {value:.4f}")
        else:
            print(f"   {key}: {value}")

    print()

def test_hvr_parameter_sensitivity():
    """æµ‹è¯•HVRå‚æ•°æ•æ„Ÿæ€§"""
    print("ğŸ›ï¸ æµ‹è¯•HVRå‚æ•°æ•æ„Ÿæ€§\n")
    
    # å›ºå®šæµ‹è¯•æ•°æ®
    seq_len = 10
    vocab_size = 50
    response_logits = torch.randn(seq_len, vocab_size)
    response_ids = torch.randint(0, vocab_size, (seq_len,))
    r_final = 1.0
    
    # æµ‹è¯•Î±å‚æ•°å½±å“
    print("ğŸ“ˆ Î± (æ¸©åº¦ç³»æ•°) å‚æ•°å½±å“:")
    alphas = [0.5, 1.0, 2.0, 4.0]
    # éœ€è¦ä½¿ç”¨ç»„æ•°æ®æ ¼å¼
    group_data = [{'logits': response_logits, 'ids': response_ids, 'r_final': r_final}]

    for alpha in alphas:
        group_returns, metrics = calculate_hvr_rewards_for_group(
            group_data, alpha=alpha, beta=0.1, lambda_hvr=0.5
        )
        print(f"  Î±={alpha}: ç»„å›æŠ¥={group_returns[0]:.4f}")
    
    print("\nğŸ“ˆ Î² (ç†µæƒ©ç½š) å‚æ•°å½±å“:")
    betas = [0.0, 0.05, 0.1, 0.2, 0.5]
    for beta in betas:
        group_returns, metrics = calculate_hvr_rewards_for_group(
            group_data, alpha=1.0, beta=beta, lambda_hvr=0.5
        )
        print(f"  Î²={beta}: ç»„å›æŠ¥={group_returns[0]:.4f}")

    print("\nğŸ“ˆ Î» (æ··åˆå› å­) å‚æ•°å½±å“:")
    lambdas = [0.0, 0.3, 0.5, 0.7, 1.0]
    for lambda_hvr in lambdas:
        group_returns, metrics = calculate_hvr_rewards_for_group(
            group_data, alpha=1.0, beta=0.1, lambda_hvr=lambda_hvr
        )
        print(f"  Î»={lambda_hvr}: ç»„å›æŠ¥={group_returns[0]:.4f}")

# ç§»é™¤ä¸å†éœ€è¦çš„æµ‹è¯•å‡½æ•°

def test_edge_cases():
    """æµ‹è¯•è¾¹ç•Œæƒ…å†µ"""
    print("\nğŸ” æµ‹è¯•è¾¹ç•Œæƒ…å†µ\n")
    
    # æµ‹è¯•æçŸ­åºåˆ—
    print("ğŸ“ æçŸ­åºåˆ— (é•¿åº¦=1):")
    short_group_data = [{'logits': torch.randn(1, 100), 'ids': torch.randint(0, 100, (1,)), 'r_final': 1.0}]
    short_returns, short_metrics = calculate_hvr_rewards_for_group(short_group_data, 1.0, 0.1, 0.5)
    print(f"  ç»„å›æŠ¥: {short_returns}")
    print(f"  æˆåŠŸç‡: {short_metrics.get('successful_count', 0) / short_metrics.get('total_count', 1)}")

    # æµ‹è¯•æç«¯R_finalå€¼
    print("\nğŸ“Š æç«¯R_finalå€¼:")
    normal_logits = torch.randn(3, 100)
    normal_ids = torch.randint(0, 100, (3,))

    extreme_r_finals = [-3.0, 3.0]
    for r_final in extreme_r_finals:
        test_group_data = [{'logits': normal_logits, 'ids': normal_ids, 'r_final': r_final}]
        returns, _ = calculate_hvr_rewards_for_group(test_group_data, 1.0, 0.1, 0.5)
        print(f"  R_final={r_final}: ç»„å›æŠ¥={returns[0]:.3f}")

    # æµ‹è¯•æ•°å€¼ç¨³å®šæ€§
    print("\nğŸ”¢ æ•°å€¼ç¨³å®šæ€§æµ‹è¯•:")
    large_logits = torch.randn(3, 100) * 10  # å¤§logits
    large_group_data = [{'logits': large_logits, 'ids': normal_ids, 'r_final': 0.0}]
    large_returns, _ = calculate_hvr_rewards_for_group(large_group_data, 1.0, 0.1, 0.5)
    print(f"  å¤§logits: NaNæ£€æŸ¥={'âŒ' if any(np.isnan(large_returns)) else 'âœ…'}")
    print(f"  å¤§logits: Infæ£€æŸ¥={'âŒ' if any(np.isinf(large_returns)) else 'âœ…'}")

def visualize_hvr_comparison():
    """å¯è§†åŒ–HVR vs æ ‡å‡†æ–¹æ³•å¯¹æ¯”"""
    try:
        print("\nğŸ“Š ç”ŸæˆHVRå¯¹æ¯”å¯è§†åŒ–...\n")
        
        seq_len = 20
        vocab_size = 100
        response_logits = torch.randn(seq_len, vocab_size)
        response_ids = torch.randint(0, vocab_size, (seq_len,))
        
        # ä¸åŒÎ»å€¼çš„HVRå¥–åŠ±
        lambdas = [0.0, 0.3, 0.5, 0.7, 1.0]
        
        plt.figure(figsize=(12, 8))
        
        test_group_data = [{'logits': response_logits, 'ids': response_ids, 'r_final': 1.0}]

        for i, lambda_hvr in enumerate(lambdas):
            group_returns, _ = calculate_hvr_rewards_for_group(
                test_group_data, alpha=1.0, beta=0.1, lambda_hvr=lambda_hvr
            )

            plt.subplot(2, 3, i + 1)
            plt.bar(0, group_returns[0])
            plt.title(f'Î» = {lambda_hvr}')
            plt.xlabel('åºåˆ—')
            plt.ylabel('ç»„å›æŠ¥')
            plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('hvr_comparison.png', dpi=150, bbox_inches='tight')
        print("  å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜ä¸º hvr_comparison.png")
        
    except ImportError:
        print("  matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å¯è§†åŒ–")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•HVRçº¯å‡€ç®—æ³•å®ç°\n")
    
    test_ervf_value_function()
    test_hvr_group_processing()
    test_hvr_parameter_sensitivity()
    test_edge_cases()
    visualize_hvr_comparison()
    
    print("ğŸ‰ HVR-GRPOé›†æˆç®—æ³•æµ‹è¯•å®Œæˆï¼")
    print("\nğŸ“‹ HVRåœ¨GRPOæ¡†æ¶ä¸­çš„ç‰¹æ€§æ€»ç»“:")
    print("  âœ… ERVFä»·å€¼å‡½æ•°: åŸºäºlogitsçš„å†…ç”Ÿä»·å€¼ + ç†µæ­£åˆ™åŒ–")
    print("  âœ… HVRå¥–åŠ±é‡å¡‘: ç¨€ç–å¥–åŠ±æŒ‡å¯¼çš„ä»·å€¼è½¨è¿¹é‡å¡‘")
    print("  âœ… GRPOç»„é—´æŠ•ç¥¨: ä¿ç•™ç»„å†…ç›¸å¯¹ä¼˜åŠ¿è®¡ç®—")
    print("  âœ… æ— éœ€critic: å®Œå…¨åŸºäºæ¨¡å‹è‡ªèº«çš„å†…ç”Ÿä»·å€¼ä¼°è®¡")
    print("  âœ… Logic RLå…¼å®¹: æ”¯æŒ{-3,-1,0,1,3}ç­‰ç¨€ç–å¥–åŠ±")
    print("  âœ… å‚æ•°å¯æ§: Î±æ§åˆ¶æ¸©åº¦ï¼ŒÎ²æ§åˆ¶ç†µæƒ©ç½šï¼ŒÎ»æ§åˆ¶é‡å¡‘å¼ºåº¦")
    print("  âœ… æ•°å€¼ç¨³å®š: ä½¿ç”¨log_softmaxç­‰ç¨³å®šè®¡ç®—")
    print("\nğŸ¯ HVR-GRPOé›†æˆå†…ç”Ÿå¥–åŠ±ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼")
