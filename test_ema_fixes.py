#!/usr/bin/env python3
"""
æµ‹è¯•EMAä¿®å¤æ˜¯å¦æœ‰æ•ˆ
"""

import torch
import numpy as np
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '.')

try:
    from verl.trainer.ppo.core_algos import apply_ema_smoothing, compute_policy_loss_with_ema
    from verl.utils.py_functional import append_to_dict
    from verl.utils.metric.utils import reduce_metrics
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€éœ€æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def test_ema_initialization_fix():
    """æµ‹è¯•EMAåˆå§‹åŒ–ä¿®å¤"""
    print("\nğŸ§ª æµ‹è¯•EMAåˆå§‹åŒ–ä¿®å¤...")
    
    batch_size, seq_len = 2, 4
    
    # åˆ›å»ºæœ‰æ˜æ˜¾å·®å¼‚çš„æƒé‡ï¼Œæ¨¡æ‹ŸçœŸå®çš„é‡è¦æ€§æƒé‡
    raw_weights_1 = torch.tensor([[1.5, 0.8, 2.1, 0.9],
                                 [1.2, 1.8, 0.7, 1.4]])
    raw_weights_2 = torch.tensor([[1.1, 1.3, 1.9, 1.0],
                                 [0.9, 1.5, 1.2, 1.6]])
    
    response_mask = torch.ones(batch_size, seq_len)
    sequence_ids = ['seq_A', 'seq_B']
    beta = 0.9
    
    print(f"ç¬¬ä¸€æ­¥åŸå§‹æƒé‡:\n{raw_weights_1}")
    print(f"ç¬¬ä¸€æ­¥æƒé‡æ–¹å·®: {(raw_weights_1 * response_mask).var().item():.6f}")
    
    # åˆå§‹åŒ–EMAçŠ¶æ€
    ema_weights_state = {}
    
    # ç¬¬ä¸€æ­¥EMA
    smoothed_weights_1, ema_metrics_1 = apply_ema_smoothing(
        raw_weights=raw_weights_1,
        ema_weights_state=ema_weights_state,
        sequence_ids=sequence_ids,
        response_mask=response_mask,
        beta=beta,
    )
    
    print(f"ç¬¬ä¸€æ­¥å¹³æ»‘æƒé‡:\n{smoothed_weights_1}")
    print(f"ç¬¬ä¸€æ­¥EMAæŒ‡æ ‡:")
    print(f"  variance_reduction_ratio: {ema_metrics_1['ema/variance_reduction_ratio']:.6f}")
    print(f"  avg_sequence_diff_l2: {ema_metrics_1['ema/avg_sequence_diff_l2']:.6f}")
    
    # ç¬¬äºŒæ­¥EMA
    print(f"\nç¬¬äºŒæ­¥åŸå§‹æƒé‡:\n{raw_weights_2}")
    print(f"ç¬¬äºŒæ­¥æƒé‡æ–¹å·®: {(raw_weights_2 * response_mask).var().item():.6f}")
    
    smoothed_weights_2, ema_metrics_2 = apply_ema_smoothing(
        raw_weights=raw_weights_2,
        ema_weights_state=ema_weights_state,
        sequence_ids=sequence_ids,
        response_mask=response_mask,
        beta=beta,
    )
    
    print(f"ç¬¬äºŒæ­¥å¹³æ»‘æƒé‡:\n{smoothed_weights_2}")
    print(f"ç¬¬äºŒæ­¥EMAæŒ‡æ ‡:")
    print(f"  variance_reduction_ratio: {ema_metrics_2['ema/variance_reduction_ratio']:.6f}")
    print(f"  avg_sequence_diff_l2: {ema_metrics_2['ema/avg_sequence_diff_l2']:.6f}")
    
    # éªŒè¯ä¿®å¤æ•ˆæœ
    print(f"\nâœ… éªŒè¯ä¿®å¤æ•ˆæœ:")
    if ema_metrics_2['ema/variance_reduction_ratio'] > 1.0:
        print(f"  âœ“ æ–¹å·®é™ä½æ¯”ä¾‹ > 1.0: {ema_metrics_2['ema/variance_reduction_ratio']:.6f}")
    else:
        print(f"  âŒ æ–¹å·®é™ä½æ¯”ä¾‹ <= 1.0: {ema_metrics_2['ema/variance_reduction_ratio']:.6f}")
    
    if ema_metrics_2['ema/avg_sequence_diff_l2'] > 0:
        print(f"  âœ“ å¹³æ»‘å¼ºåº¦ > 0: {ema_metrics_2['ema/avg_sequence_diff_l2']:.6f}")
    else:
        print(f"  âŒ å¹³æ»‘å¼ºåº¦ <= 0: {ema_metrics_2['ema/avg_sequence_diff_l2']:.6f}")
    
    return ema_metrics_2

def test_uid_handling():
    """æµ‹è¯•uidå¤„ç†é€»è¾‘"""
    print(f"\nğŸ” æµ‹è¯•uidå¤„ç†é€»è¾‘...")
    
    # æ¨¡æ‹ŸDataProtoå¯¹è±¡
    class MockDataProto:
        def __init__(self, has_uid=True):
            self.non_tensor_batch = {}
            if has_uid:
                self.non_tensor_batch["uid"] = np.array(["real_seq_1", "real_seq_2", "real_seq_3"], dtype=object)
    
    # æµ‹è¯•1: æœ‰uidçš„æƒ…å†µ
    print("æµ‹è¯•1: æœ‰uidçš„æƒ…å†µ")
    data_with_uid = MockDataProto(has_uid=True)
    
    if hasattr(data_with_uid, 'non_tensor_batch') and "uid" in data_with_uid.non_tensor_batch:
        uid_array = data_with_uid.non_tensor_batch["uid"]
        sequence_ids = uid_array.tolist() if hasattr(uid_array, 'tolist') else list(uid_array)
        print(f"  âœ“ æˆåŠŸè·å–uid: {sequence_ids}")
    else:
        print(f"  âŒ æœªèƒ½è·å–uid")
    
    # æµ‹è¯•2: æ²¡æœ‰uidçš„æƒ…å†µ
    print("æµ‹è¯•2: æ²¡æœ‰uidçš„æƒ…å†µ")
    data_without_uid = MockDataProto(has_uid=False)
    
    if hasattr(data_without_uid, 'non_tensor_batch') and "uid" in data_without_uid.non_tensor_batch:
        uid_array = data_without_uid.non_tensor_batch["uid"]
        sequence_ids = uid_array.tolist() if hasattr(uid_array, 'tolist') else list(uid_array)
        print(f"  è·å–åˆ°uid: {sequence_ids}")
    else:
        batch_size = 3
        sequence_ids = [f"temp_seq_{i}" for i in range(batch_size)]
        print(f"  âœ“ ä½¿ç”¨ä¸´æ—¶åºåˆ—ID: {sequence_ids}")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹æµ‹è¯•EMAä¿®å¤...")
    
    try:
        # æµ‹è¯•EMAåˆå§‹åŒ–ä¿®å¤
        ema_metrics = test_ema_initialization_fix()
        
        # æµ‹è¯•uidå¤„ç†
        test_uid_handling()
        
        print(f"\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        print(f"\nğŸ“‹ ä¿®å¤æ€»ç»“:")
        print(f"  1. âœ“ ä¿®å¤äº†EMAåˆå§‹åŒ–é—®é¢˜ï¼ˆä½¿ç”¨å½“å‰æƒé‡è€Œä¸æ˜¯1.0ï¼‰")
        print(f"  2. âœ“ ä¿®å¤äº†uidå­—æ®µä¼ é€’é—®é¢˜")
        print(f"  3. âœ“ æ·»åŠ äº†æ›´å¥½çš„uidè·å–é€»è¾‘")
        print(f"  4. âœ“ ä¿æŒäº†ä¸´æ—¶åºåˆ—IDçš„å›é€€æœºåˆ¶")
        
        print(f"\nğŸ”§ ç°åœ¨é‡æ–°è¿è¡Œè®­ç»ƒåº”è¯¥çœ‹åˆ°:")
        print(f"   - æ›´å°‘çš„ 'Warning: No uid found' æ¶ˆæ¯")
        print(f"   - variance_reduction_ratio > 1.0")
        print(f"   - smoothing_strength > 0")
        print(f"   - WandBä¸­çš„å®Œæ•´EMAæŒ‡æ ‡")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
