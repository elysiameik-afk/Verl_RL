#!/usr/bin/env python3
"""
å¿«é€Ÿæµ‹è¯•EMAå®ç°æ˜¯å¦å·¥ä½œ
"""

import torch
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '.')

try:
    from verl.trainer.ppo.core_algos import apply_ema_smoothing, compute_policy_loss_with_ema
    print("âœ… æˆåŠŸå¯¼å…¥EMAå‡½æ•°")
except ImportError as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    sys.exit(1)

def test_ema_basic():
    """åŸºç¡€EMAæµ‹è¯•"""
    print("\nğŸ§ª å¼€å§‹åŸºç¡€EMAæµ‹è¯•...")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    batch_size, seq_len = 2, 5
    raw_weights = torch.tensor([[2.0, 1.5, 3.0, 0.8, 1.2],
                               [1.8, 2.2, 0.9, 1.6, 2.1]])
    response_mask = torch.ones(batch_size, seq_len)
    sequence_ids = ['test_seq_1', 'test_seq_2']
    beta = 0.9
    
    print(f"åŸå§‹æƒé‡:\n{raw_weights}")
    print(f"åŸå§‹æƒé‡æ–¹å·®: {(raw_weights * response_mask).var().item():.6f}")
    
    # åˆå§‹åŒ–EMAçŠ¶æ€
    ema_weights_state = {}
    
    # ç¬¬ä¸€æ¬¡å¹³æ»‘
    smoothed_weights, ema_metrics = apply_ema_smoothing(
        raw_weights=raw_weights,
        ema_weights_state=ema_weights_state,
        sequence_ids=sequence_ids,
        response_mask=response_mask,
        beta=beta,
    )
    
    print(f"å¹³æ»‘åæƒé‡:\n{smoothed_weights}")
    print(f"å¹³æ»‘åæƒé‡æ–¹å·®: {ema_metrics['ema/smoothed_weights_variance']:.6f}")
    print(f"æ–¹å·®é™ä½æ¯”ä¾‹: {ema_metrics['ema/variance_reduction_ratio']:.6f}")
    print(f"å¹³æ»‘å¼ºåº¦: {ema_metrics['ema/smoothing_strength']:.6f}")
    
    # ç¬¬äºŒæ¬¡å¹³æ»‘ï¼ˆæ¨¡æ‹Ÿä¸‹ä¸€æ­¥ï¼‰
    new_raw_weights = torch.tensor([[1.5, 2.0, 2.5, 1.0, 1.8],
                                   [2.1, 1.7, 1.3, 2.0, 1.9]])
    
    smoothed_weights_2, ema_metrics_2 = apply_ema_smoothing(
        raw_weights=new_raw_weights,
        ema_weights_state=ema_weights_state,
        sequence_ids=sequence_ids,
        response_mask=response_mask,
        beta=beta,
    )
    
    print(f"\nç¬¬äºŒæ­¥åŸå§‹æƒé‡:\n{new_raw_weights}")
    print(f"ç¬¬äºŒæ­¥å¹³æ»‘æƒé‡:\n{smoothed_weights_2}")
    print(f"ç¬¬äºŒæ­¥æ–¹å·®é™ä½æ¯”ä¾‹: {ema_metrics_2['ema/variance_reduction_ratio']:.6f}")
    
    return True

def test_policy_loss():
    """æµ‹è¯•ç­–ç•¥æŸå¤±è®¡ç®—"""
    print("\nğŸ¯ æµ‹è¯•ç­–ç•¥æŸå¤±è®¡ç®—...")
    
    batch_size, seq_len = 2, 4
    old_log_prob = torch.tensor([[-0.1, -0.2, -0.15, -0.18],
                                [-0.12, -0.25, -0.11, -0.20]])
    log_prob = torch.tensor([[-0.09, -0.22, -0.14, -0.19],
                            [-0.11, -0.23, -0.13, -0.21]])
    advantages = torch.tensor([[0.5, -0.3, 0.2, 0.1],
                              [-0.2, 0.4, -0.1, 0.3]])
    response_mask = torch.ones(batch_size, seq_len)
    sequence_ids = ['policy_seq_1', 'policy_seq_2']
    
    ema_weights_state = {}
    
    # æµ‹è¯•å¸¦EMAçš„ç­–ç•¥æŸå¤±
    pg_loss, pg_clipfrac, ppo_kl, pg_clipfrac_lower, ema_metrics = compute_policy_loss_with_ema(
        old_log_prob=old_log_prob,
        log_prob=log_prob,
        advantages=advantages,
        response_mask=response_mask,
        cliprange=0.2,
        ema_weights_state=ema_weights_state,
        sequence_ids=sequence_ids,
        beta=0.9,
        use_ema=True,
    )
    
    print(f"ç­–ç•¥æŸå¤±: {pg_loss.item():.6f}")
    print(f"è£å‰ªæ¯”ä¾‹: {pg_clipfrac.item():.6f}")
    print(f"PPO KL: {ppo_kl.item():.6f}")
    print(f"æ–¹å·®é™ä½æ¯”ä¾‹: {ema_metrics['ema/variance_reduction_ratio']:.6f}")
    print(f"å¹³æ»‘å¼ºåº¦: {ema_metrics['ema/smoothing_strength']:.6f}")
    
    return True

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹EMAåŠŸèƒ½æµ‹è¯•...")
    
    try:
        test_ema_basic()
        test_policy_loss()
        print("\nâœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼EMAå®ç°æ­£å¸¸å·¥ä½œã€‚")
        print("\nğŸ“‹ ç°åœ¨ä½ å¯ä»¥è¿è¡Œè®­ç»ƒ:")
        print("   bash exp/qwen2.5kk1_ema.sh")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
