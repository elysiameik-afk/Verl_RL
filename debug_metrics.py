#!/usr/bin/env python3
"""
è°ƒè¯•metricsä¼ é€’é—®é¢˜
"""

import torch
import sys
import os

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, '.')

from verl.utils.py_functional import append_to_dict
from verl.utils.metric.utils import reduce_metrics

def test_metrics_flow():
    """æµ‹è¯•metricsçš„å®Œæ•´æµç¨‹"""
    print("ğŸ” æµ‹è¯•metricsä¼ é€’æµç¨‹...")
    
    # æ¨¡æ‹ŸActorä¸­çš„metricså­—å…¸
    metrics = {}
    
    # æ¨¡æ‹ŸEMA metricsï¼ˆå°±åƒæˆ‘ä»¬åœ¨apply_ema_smoothingä¸­ç”Ÿæˆçš„ï¼‰
    ema_metrics = {
        'ema/raw_weights_variance': 2.5,
        'ema/smoothed_weights_variance': 1.8,
        'ema/variance_reduction_ratio': 1.39,
        'ema/smoothing_strength': 0.28,
        'ema/beta': 0.9,
        'ema/use_ema': True,
    }
    
    print(f"åŸå§‹EMA metrics: {ema_metrics}")
    
    # ä½¿ç”¨append_to_dictæ·»åŠ metricsï¼ˆå°±åƒåœ¨Actorä¸­åšçš„ï¼‰
    append_to_dict(metrics, ema_metrics)
    
    print(f"æ·»åŠ åˆ°metricså: {metrics}")
    
    # æ¨¡æ‹Ÿå…¶ä»–metrics
    other_metrics = {
        'actor/pg_loss': 0.15,
        'actor/pg_clipfrac': 0.02,
        'actor/ppo_kl': 0.001,
    }
    
    append_to_dict(metrics, other_metrics)
    
    print(f"æ·»åŠ å…¶ä»–metricså: {metrics}")
    
    # æ¨¡æ‹Ÿtrainerä¸­çš„reduce_metricsè°ƒç”¨
    reduced_metrics = reduce_metrics(metrics)
    
    print(f"reduceåçš„metrics: {reduced_metrics}")
    
    # éªŒè¯EMA metricsæ˜¯å¦æ­£ç¡®ä¼ é€’
    expected_ema_keys = [
        'ema/raw_weights_variance',
        'ema/smoothed_weights_variance', 
        'ema/variance_reduction_ratio',
        'ema/smoothing_strength',
        'ema/beta',
        'ema/use_ema'
    ]
    
    print(f"\nâœ… æ£€æŸ¥EMA metricsæ˜¯å¦å­˜åœ¨:")
    for key in expected_ema_keys:
        if key in reduced_metrics:
            print(f"  âœ“ {key}: {reduced_metrics[key]}")
        else:
            print(f"  âŒ {key}: ç¼ºå¤±")
    
    return reduced_metrics

def test_multiple_batches():
    """æµ‹è¯•å¤šä¸ªbatchçš„metricsèšåˆ"""
    print(f"\nğŸ”„ æµ‹è¯•å¤šä¸ªbatchçš„metricsèšåˆ...")
    
    metrics = {}
    
    # æ¨¡æ‹Ÿ3ä¸ªmicro-batchçš„EMA metrics
    for batch_idx in range(3):
        ema_metrics = {
            'ema/raw_weights_variance': 2.5 + batch_idx * 0.1,
            'ema/smoothed_weights_variance': 1.8 + batch_idx * 0.05,
            'ema/variance_reduction_ratio': 1.39 + batch_idx * 0.02,
            'ema/beta': 0.9,
        }
        
        print(f"Batch {batch_idx} EMA metrics: {ema_metrics}")
        append_to_dict(metrics, ema_metrics)
    
    print(f"\nèšåˆå‰çš„metrics: {metrics}")
    
    # Reduce metrics
    reduced_metrics = reduce_metrics(metrics)
    
    print(f"èšåˆåçš„metrics: {reduced_metrics}")
    
    # éªŒè¯å¹³å‡å€¼è®¡ç®—
    expected_variance = (2.5 + 2.6 + 2.7) / 3
    actual_variance = reduced_metrics['ema/raw_weights_variance']
    
    print(f"\néªŒè¯å¹³å‡å€¼è®¡ç®—:")
    print(f"  æœŸæœ›çš„raw_weights_variance: {expected_variance:.3f}")
    print(f"  å®é™…çš„raw_weights_variance: {actual_variance:.3f}")
    print(f"  å·®å¼‚: {abs(expected_variance - actual_variance):.6f}")
    
    return reduced_metrics

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹è°ƒè¯•metricsä¼ é€’...")
    
    try:
        test_metrics_flow()
        test_multiple_batches()
        
        print(f"\nâœ… metricsä¼ é€’æµ‹è¯•é€šè¿‡ï¼")
        print(f"\nğŸ“ ä¿®å¤è¯´æ˜:")
        print(f"  - ä½¿ç”¨ append_to_dict() è€Œä¸æ˜¯ metrics.update()")
        print(f"  - è¿™æ ·metricsä¼šè¢«æ­£ç¡®æ·»åŠ åˆ°åˆ—è¡¨ä¸­")
        print(f"  - trainerä¸­çš„ reduce_metrics() ä¼šè®¡ç®—å¹³å‡å€¼")
        print(f"\nğŸ”§ ç°åœ¨é‡æ–°è¿è¡Œè®­ç»ƒï¼ŒEMAæŒ‡æ ‡åº”è¯¥ä¼šå‡ºç°åœ¨WandBä¸­ï¼")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
